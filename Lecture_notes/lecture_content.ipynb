{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "\n",
    "# Lecture 1 - Introduction\n",
    "\n",
    "## what is deeplearning?\n",
    "- finding patterns in data\n",
    "- finding the correct representations data should be in to perform the task given\n",
    "- examples: learning to predict the category(label) of an image\n",
    "\n",
    "## Machine Learning:\n",
    "- A study of computer programmes that improve their performance at some **task** with **experience** (data)\n",
    "\n",
    "## Linear Regression:\n",
    "An example: Weather prediction (supervised learning) \n",
    "- Task: Predict air temperature (real number)\n",
    "- Experience: Historic data of air temperature (train data)\n",
    "- performance measure: Deviation of the forecast (test data)\n",
    "\n",
    "Given training data $\\left\\{(X_i, Y_i)\\right\\}^n_{i=1}$      $X_i \\epsilon \\mathbb{R}_d, y_i, \\epsilon \\mathbb{R}$\n",
    "\n",
    "Find a model $\\hat{y} = f(x)$\n",
    "\n",
    "Such that $f(x) \\approx y$ on test data\n",
    "\n",
    "- The idea of machine learning is to perform estimate function $f$\n",
    "    - In other words, the aim is to estimate $y$ using $x$\n",
    "    - $\\hat{y} = f(x)$\n",
    "    \n",
    "<img src=\"./images/function_estimation.png\">\n",
    "\n",
    "## Linear Model!\n",
    "\n",
    "- Given training data $\\left\\{(X_i,Y_i) ~ p\\; i.i.d\\right\\}^n_{i=1}$ \n",
    "    - p i.i.d being data taken from all available data\n",
    "- assuming linear model $\\hat{y} = f_{w,b}(x) = w^Tx+b$\n",
    "    - prediction function follows (node weights * )\n",
    "- Find optimal parameters w,b by minimising empitical loss\n",
    "\n",
    "- $\\hat{L}(w,b) = \\frac{1}{n}\\Sigma^{n}_{i=1}(w^Tx_i + b - y_i)^2$\n",
    "    \n",
    "    - $w^Tx_i + b$ being the function prediction\n",
    "    - The ground truth $y_i$ is subtracted to find out how far off the predictions were\n",
    "    - This is squared and devided by the number of observations $n$\n",
    "    - This gives the predicted prediction line\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Base mathematics - Linear algebra\n",
    "\n",
    "## Scalars\n",
    "- A single number\n",
    "    - denoted as a lower case letter\n",
    "    - We may say \"$Let\\: s\\: \\epsilon\\: \\mathbb{R}\\: be\\: the\\: slope\\: of\\: the\\: line$\" when defining a scalar real-value\n",
    "    - We may say \"$Let\\: s\\: \\epsilon\\: \\mathbb{N}\\: be\\: the\\: number\\: of\\: units$\" when defining a scalar natural number\n",
    "\n",
    "## Vectors\n",
    "- An array of elements\n",
    "    - denoted by bold lower case letter.\n",
    "        - indexes denoted with italic lower case letter and its corresponding subscript.\n",
    "    - Numbers are arranged in order\n",
    "    - Each element is identified by its index\n",
    "    - If the vector is a $\\mathbb{R}$ and has $n$ elements it is denoted $\\mathbb{R}^n$ by taking the Cartesian product.\n",
    "\n",
    "- e.g. $\\begin{align}\n",
    "        \\mathbf{x} &= \\begin{bmatrix}\n",
    "           x_1 \\\\\n",
    "           x_2 \\\\\n",
    "           \\vdots \\\\\n",
    "           x_3\n",
    "         \\end{bmatrix}\n",
    "        \\end{align}$\n",
    "\n",
    "### Cartesian Product\n",
    "- $\\mathbf{a}\\: \\times\\: \\mathbf{b}$ will give you all possible configuration of sets $\\mathbf{a}$ and $\\mathbf{b} as a new set$\n",
    "\n",
    "Vectors identify a point in space, each element giving a differenct co-oridinate of the space.\n",
    "When indexing particular elements from a set, this notation can be used to single out the specified indecies.\n",
    "- $indicies \\: x_1, x_2, x_3$ can be accessed using $S - \\left\\{1, 2, 3\\right\\}$ writting it as $\\mathbf{x}_S$\n",
    "    - The \"$-$\" represents the complement of a set\n",
    "    - Compliment can also be used as $x_{-1}$ representing all elements of $\\mathbf{x}$ except for $x_1$\n",
    "    - $x_{-S}$ repersents all elements of $\\mathbf{x}$ except for $x_1, x_2, x_3$\n",
    "\n",
    "## Matrices\n",
    "- A 2-D array of numbers\n",
    "    - Denoted with bold uppercase letters\n",
    "    - An array of height of m and width of n is denoted $\\mathbb{R}^{m \\times n}$\n",
    "    - Indecies are written in italic but not bold \n",
    "        - e.g. $\\textit{A}_{1,1}$\n",
    "    - e.g. $\\begin{align}\n",
    "        \\mathbf{x} &= \\begin{bmatrix}\n",
    "           x_{1,1} & x_{1,2} & x_{1,3} \\\\\n",
    "           x_{2,1} & x_{2,2} & x_{2,3} \\\\\n",
    "           \\vdots \\\\\n",
    "           x_{n,1} & x_{n,2} & x_{n,3}\n",
    "         \\end{bmatrix}\n",
    "        \\end{align}$\n",
    "    - \":\" is used to reference an entire axis. e.g. $\\textbf{A}_{i,:}$ refers to the 'i'th vertical column and $\\textbf{A}_{:,i}$ refers to the 'i'th horizontal column.\n",
    "    - functions applied to the matrix can be indexed directly\n",
    "        - e.g. $\\textit{f}(\\textbf{A})_{i,j}$\n",
    "\n",
    "## Tensors\n",
    "- Tensors are arrays with more than two axes.\n",
    "    - They are denoted similarly to Matrices\n",
    "    - e.g. $\\textbf{A}_{i,j,k}$\n",
    "\n",
    "## Transpose (A matrix operation)\n",
    "- Mirroring a matrix from its main diagonal (main diagonal is from $x_{1,1}$ through $x_{2,2} forming a even cut when the matrix has a width equal to its height)\n",
    "\n",
    "e.g.\n",
    "\n",
    "$\\begin{align}\n",
    "    \\mathbf{x} &= \\begin{bmatrix}\n",
    "        4 & 7 \\\\\n",
    "        5 & 8 \\\\\n",
    "        6 & 9\n",
    "    \\end{bmatrix}\n",
    "\\end{align}$\n",
    "\n",
    "Will be converted to:\n",
    "\n",
    "$\\begin{align}\n",
    "    \\mathbf{x} &= \\begin{bmatrix}\n",
    "        4 & 5 & 6\\\\\n",
    "        5 & 8 & 9 \\\\\n",
    "    \\end{bmatrix}\n",
    "\\end{align}$\n",
    "\n",
    "- Transpose of $\\textbf{A}$ is denoted $/textbf{A}^T$ \n",
    "\n",
    "We can convert a column of a matrix into a regular vector using Transpose\n",
    "- $x - [x_1, x_2, x_3]^T$\n",
    "    - Again, dash representing complement\n",
    "\n",
    "## Adding Matrices\n",
    "Matrices can be added together given they have the same shape.\n",
    "e.g. $\\textbf{A} - \\textbf{A} + \\textbf{B}$ where $C\\textbf{C}_{i,j} - \\textbf{A}_{i,j} + \\textbf{A}_{i,j}$\n",
    "\n",
    "## Multiplying and Adding Scalars to Matrices\n",
    "- Done by performing calculations on each elements of the matrix\n",
    "    - $\\textbf{C} - a \\cdot \\textbf{B} + c$ where $\\textbf{D} - a \\cdot B_{i,j} + c$\n",
    "\n",
    "Deeplearning unconventional notation for matrix addition:\n",
    "- It yeilds a new matrix\n",
    "- \n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}